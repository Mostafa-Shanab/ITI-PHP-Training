<!DOCTYPE html>

<html style="
    border-left: 105px solid rgb(170, 184, 193);
    border-right: 105px solid rgb(170, 184, 193);
    font-family: Helvetica, Arial, sans-serif;
    ">

<head>
    <title>Assignment 1</title>
</head>

<body style="margin: 105px">
    <p style="color: #AAC3DC; font-size: smaller;">Company</p>
    <h1>X's report in compliance with <br />Regulation (EU) 2021/1232</h1>
    <p>
        <span style="color: #AAC3DC; font-size: smaller;">Sunday, 19 May 2024</span>
        <a href="https://x.com/?lang=en"><img
                src="https://uxwing.com/wp-content/themes/uxwing/download/brands-and-social-media/x-social-media-black-icon.png"
                width="15px" /></a>
        <a href="https://www.facebook.com/"><img
                src="https://static.vecteezy.com/system/resources/thumbnails/022/257/063/small/icon-media-social-facebook-free-vector.jpg"
                width="15px" /></a>
        <a href="https://www.linkedin.com/login/ar">
            <img src="https://t4.ftcdn.net/jpg/06/04/68/99/360_F_604689984_50VpKqlFBCOvSC54HM8Z92uneHoIJ1F9.jpg"
                width="15px" />
        </a>
        <a href="#">
            <img src="https://cdn-icons-png.flaticon.com/128/10146/10146565.png" width="15px" />
        </a>
    </p>
    <br /><br /><br />
    <p>
        <i><strong>Submitted and uploaded on 19 May 2024</strong></i>
    </p>
    <p>
        <strong>X REPORT (PERIOD OF JANUARY 1 2023 - DECEMBER 31 2023)</strong>
    </p>
    <p style="max-width: 55%">
        Under Article 3(1)(g)(vii) of Regulation (EU) 2021/1232 concerning a
        temporary derogation from certain provisions of Directive 2002/58/EC
        regarding the use of technologies by providers of number-independent
        interpersonal communication services for processing personal and other
        data to combat online child sexual abuse (‚ÄúEU CSAM Derogation‚Äù), which
        entered into force on 2 August 2021, Twitter International Unlimited
        Company (‚ÄúTIUC‚Äù) is required to compile, publish, and submit this report
        to both the Irish Data Protection Commission (‚ÄúIDPC‚Äù) and the European
        Commission (‚ÄúEC‚Äù). This report specifically covers the period from 1
        January 2023 to 31 December 2023, inclusive.
    </p>
    <p style="max-width: 55%">
        Please note that the content of this report is specifically tailored to
        address measures within the purview of the EU CSAM Derogation. As such, it
        focuses on the actions and initiatives directly related to the regulation
        and its requirements for combating online Child Sexual Exploitation
        (‚ÄúCSE‚Äù). This report does not encompass the entirety of efforts and
        measures employed by our platform to protect children.
    </p>
    <h3>Overview</h3>
    <p style="max-width: 55%">
        ùïè is committed to facilitating the public conversation in a responsible
        manner. Integral to this commitment is ùïè‚Äôs
        <a href="https://help.x.com/en/rules-and-policies/child-safety">zero tolerance policy towards CSE on our
            platform</a>. We strictly prohibit any content that features, promotes or glorifies
        CSE, including but not limited to, media, text, illustrated content, or
        computer-generated images.
    </p>
    <p style="max-width: 55%">
        Our policy underscores that the act of viewing, sharing, or linking to CSE
        material not only contributes to the re-victimisation of the depicted
        minors but also violates our platform‚Äôs guidelines. This stance extends to
        any content that could further contribute to the victimisation of children
        by promoting or glorifying CSE.
    </p>
    <h3>Our Approach</h3>
    <p style="max-width: 55%">
        We are deeply committed to protecting children globally from CSE. Our
        approach encompassess the development of advanced technological solutions,
        comprehensive training of our content moderators, continued support for
        law enforcement, and ongoing partnerships to address and prevent CSE
        effectively.
    </p>
    <p style="max-width: 55%">
        Our approach integrates machine learning algorithms with human oversight
        to efficiently identify and assess content that potentially violates our
        policies against CSE. Our systems flag content for review, enabling our
        human moderators to consider crucial contextual information in their
        decision-making process. This work is led by an international,
        cross-functional team that provides 24-hour monitoring in multiple
        languages, ensuring rapid and effective responses to emerging threats.
    </p>
    <p style="max-width: 55%">
        Upon identification of CSE media, including images, videos, or any content
        that promotes child exploitation, we remove such material from our
        platform without further notice and report it to The National Center for
        Missing & Exploited Children (‚ÄúNCMEC‚Äù). NCMEC plays a pivotal role in
        coordinating with law enforcement agencies worldwide to support
        investigations and legal actions. Benefiting from robust partnerships with
        law enforcement bodies, NGOs, and the INHOPE network, NCMEC is
        instrumental in our collective efforts to eradicate CSE.
    </p>
    <p style="max-width: 55%">
        In December 2022, we embarked on a significant partnership with Thorn,
        utilising its Safer product to substantially increase our capacity to
        identify, remove, and report violative content. Further solidifying our
        stance against CSE, we are further partnering with the Tech Coalition and
        WeProtect. These partnerships facilitate critical information sharing on
        emerging threats and behavioural patterns associated with CSE, enabling us
        to stay ahead of potential risks and adapt our strategies accordingly.
    </p>
    <p style="max-width: 55%">
        Our dedication to safeguarding children extends to continuous investment
        in both technology and talent. We are committed to enhancing our detection
        and response mechanisms, actively seeking out advanced technologies from
        third-party developers that can enhance our protective measures.
    </p>
    <p style="max-width: 55%">
        We also have instituted an appeal process. This mechanism ensures that
        decisions to remove content or suspend accounts can be reviewed,
        safeguarding against inaccuracies and maintaining our commitment to
        fairness and transparency.
    </p>
    <p style="max-width: 55%">
        For further information on our approach please visit
        <a href="https://help.x.com/en/rules-and-policies/child-safety">this page</a>.
    </p>
    <p>---</p>
    <h3 style="max-width: 55%">(1) the type and volumes of data processed;</h3>
    <p style="max-width: 55%">
        During the reporting period of 1 January 2023, to 31 December 2023, TIUC
        took significant action in its fight against CSE. We suspended 12.4
        million accounts for violations related to our CSE policies globally, a
        substantial increase from 2.3 million accounts in 2022. In the EU, we
        suspended more than 700K accounts during the reporting period.
        Furthermore, we submitted 870,000 reports to NCMEC globally, making a
        significant uptick in our reporting efforts, including our first
        fully-automated report. This volume is over eight times the number
        reported in 2022. It is important to note that TIUC does not currently
        track accounts reviewed but not actioned for policy violations. However,
        we may process personal data, including account details, text, and media,
        to investigate potential CSE policy violations.
    </p>
    <h3 style="max-width: 55%">
        (2) the specific ground relied on for the processing pursuant to
        Regulation (EU) 2016/679;
    </h3>
    <p style="max-width: 55%">
        The specific grounds for processing personal data by TIUC are detailed in
        <a href="https://x.com/en/privacy">ùïè‚Äôs Privacy Policy</a> and
        <a href="https://help.twitter.com/en/rules-and-policies/data-processing-legal-bases">Additional information
            about data processing</a>, aligning with Regulation (EU) 2016/679 (‚ÄúGDPR‚Äù).
    </p>
    <h3 style="max-width: 55%">
        (3) the ground relied on for transfers of personal data outside the Union
        pursuant to Chapter V of Regulation (EU) 2016/679, where applicable;
    </h3>
    <p style="max-width: 55%">
        Consistent with Chapter V of the GDPR, ùïè relies on the European
        Commission‚Äôs adequacy decision or Standard Contractual Clauses (‚ÄúSCCs‚Äù)
        for the transfers of personal data outside the European Union, as detailed
        in
        <a href="https://x.com/en/privacy">ùïè‚Äôs Privacy Policy</a>.
    </p>
    <h3 style="max-width: 55%">
        (4) the number of cases of online child sexual abuse identified,
        differentiating between online child sexual abuse material and
        solicitation of children;
    </h3>
    <p style="max-width: 55%">
        While all reported violations contravene
        <a href="https://help.x.com/en/rules-and-policies/child-safety">ùïè‚Äôs CSE policy</a>, we currently lack the
        capability to categorically distinguish between
        online sexual abuse material and the specific context of each piece of
        material, such as the solicitation of children. Nonetheless, the 12.4
        million account suspensions during this period reflect our commitment to
        combating all forms of CSE.
    </p>
    <h3 style="max-width: 55%">
        (5) The number of cases in which a user has lodged a complaint with the
        internal redress mechanism or with a judicial authority and the outcome of
        such complaints
    </h3>
    <p style="max-width: 55%">
        In 2023 we received 224k appeals in the EU for CSE-related actions.
    </p>
    <h3 style="max-width: 55%">
        (6) The numbers and ratios of errors (false positives) of the different
        technologies used
    </h3>
    <p style="max-width: 55%">
        In 2023 we reversed 1,721 CSE suspensions in the EEA. Of these reversals,
        210 of the original suspensions were made by automation and 1,511 were
        applied manually. In 2023 we made 500k automated and 200k manual CSE
        suspensions in the EEA, which translates to a precision of over 99% for
        each method.
    </p>
    <h3 style="max-width: 55%">
        (7) The measures applied to limit the error rate and the error rate
        achieved
    </h3>
    <p style="max-width: 55%">
        We continually provide training to our agents to ensure consistent
        enforcement of our policies, thereby guaranteeing a high level of
        accuracy. For automated defences we sample potential actions and label to
        determine error rate before launch. We deploy a variety of stopgaps to
        ensure we don‚Äôt over-enforce or enforce on high trust accounts. Based on
        our suspensions and appeals volume, we achieved an error rate of less than
        0.1%.
    </p>
    <h3 style="max-width: 55%">
        (8) the retention policy and the data protection safeguards applied
        pursuant to Regulation (EU) 2016/679;
    </h3>
    <p style="max-width: 55%">
        TIUC‚Äôs data retention policies are outlined in our
        <a href="https://x.com/en/privacy">ùïè's Privacy Policy</a>. We adhere to
        ISO standards for security and privacy, undergoing regular third-party
        audits as needed to ensure the robust protection of the processed data.
    </p>
    <h3 style="max-width: 55%">
        (9) the names of the organisations acting in the public interest against
        child sexual abuse with which data has been shared pursuant to this
        Regulation
    </h3>
    <p style="max-width: 55%">
        The National Center for Missing and Exploited Children (‚ÄúNCMEC‚Äù) in the
        United States of America (<a href="https://www.missingkids.org/home">https://www.missingkids.org/</a>).
    </p>
</body>

</html>